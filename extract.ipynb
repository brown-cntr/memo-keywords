{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b245cc6b-8533-4512-89b8-65120828c515",
   "metadata": {},
   "source": [
    "# Use LLM to extract certain data based on definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2fb6ac-f38c-443c-8f13-502c462b6000",
   "metadata": {},
   "source": [
    "This notebook reads in certain state bills and uses LLM to extract certain data based on some definitions, e.g. whether a bill's scope is on government's use of AI/ADS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d0870-36a8-4572-9801-d02eded69ed6",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adda552-2225-414e-8eb9-99c0e121056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997fddda-1c78-4d44-bfa7-5900dbef25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515d67d-7fc6-40d4-82c6-07849c6165a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c697614-5522-47c3-8ad0-4fc232a2a594",
   "metadata": {},
   "source": [
    "## Read and select data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f4ca7-9e31-458a-b471-3b9fb6792b5f",
   "metadata": {},
   "source": [
    "The following selects curated data (i.e. bills that have met certain threshold of AI/ADS-related words, usually relative to the length of the document). However, to widen the search, below also attempts to included bills not marked by such curation based on threshold, as long as they contain `artificial intelligence` or `automat(ed|ic) decision`. Additionally, only **state** bills proposed from 2023-2024 are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfabfb-53f9-4867-92f8-323012e727ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/bill_data.json')\n",
    "df['text'] = df['text'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cef1dd-67f6-49ef-a2cc-63df9a0fed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_ai_ads'] = ~df.filter(regex='^query_').agg(\n",
    "    lambda x: ' '.join(list(set(np.concatenate(list(x))))),\n",
    "    axis=1\n",
    ").str.extract(\n",
    "    r'(artificial intelligence|automat\\w* decision)',\n",
    "    expand=False\n",
    ").isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4d7b0-48da-4ba0-a934-355c202e7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .query(\n",
    "        '''\n",
    "        (curated or has_ai_ads)\n",
    "        and\n",
    "        first_date.str.contains(\"2023|2024\", regex=True)\n",
    "        and \n",
    "        jurisdiction_code != \"US\"\n",
    "    '''.replace('\\n',' ').strip()\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2455e2-7e97-48e3-a607-60a57edf3f59",
   "metadata": {},
   "source": [
    "## Split text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff5533-3ccc-44a7-9c58-d5bcceba5c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T17:21:49.064336Z",
     "iopub.status.busy": "2024-04-16T17:21:49.063897Z",
     "iopub.status.idle": "2024-04-16T17:21:49.070285Z",
     "shell.execute_reply": "2024-04-16T17:21:49.068839Z",
     "shell.execute_reply.started": "2024-04-16T17:21:49.064296Z"
    }
   },
   "source": [
    "Some bills are quite long, so break into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e05d9-abe1-42b6-8fbf-7cfb85f81d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=10000,\n",
    "    chunk_overlap=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176cf71-764a-4071-8fe6-d50e5711e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    metadata = {\n",
    "        k: v for k, v in row.items() \n",
    "        if k not in ['text', 'raw_text', 'abstract']\n",
    "    }\n",
    "    \n",
    "    chunks = text_splitter.split_documents([Document(page_content=text)])\n",
    "    docs.append(dict(\n",
    "        bill_id = metadata['bill_id'],\n",
    "        chunks = chunks,\n",
    "        metadata = metadata,\n",
    "        num_chunks = len(chunks)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52288755-8e27-4311-8e35-b88b49eb4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs), sum([len(x['chunks']) for x in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1161a3-93ea-4b6b-a27e-b33ef03850eb",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec429d93-b4b1-4b9e-b414-35f32dc6b446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T17:22:21.546907Z",
     "iopub.status.busy": "2024-04-16T17:22:21.546619Z",
     "iopub.status.idle": "2024-04-16T17:22:21.552072Z",
     "shell.execute_reply": "2024-04-16T17:22:21.550885Z",
     "shell.execute_reply.started": "2024-04-16T17:22:21.546880Z"
    }
   },
   "source": [
    "These are some definitions and intructions to handle them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efc682-536d-4b30-a544-dd96dfb7401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = [\n",
    "    dict(\n",
    "        name = \"has_government_scope\",\n",
    "        description = '''\\\n",
    "Indicates whether the bill has government scope: \\\n",
    "a bill has government scope if it governs the government's use of artificial intelligence (AI) or \\\n",
    "automated decision systems (ADS) in its operations. \\\n",
    "This scope specifically focuses on the **government**'s use and procurement of these technologies.''',\n",
    "        instruction = '''\\\n",
    "- First, answer only \"Yes\" or \"No\".\n",
    "- If \"Yes\", also include 1-2 sentence excerpts from the text to support the government scope, \\\n",
    "label variable as `excerpt_government_scope`.'''\n",
    "    ),\n",
    "    dict(\n",
    "        name = \"has_ai_governance_body\",\n",
    "        description = '''\\\n",
    "Indicates whether the bill designates, indicates or establishes an AI governance body: \\\n",
    "an AI governance body is a group of people in the within a government entity or organization that \\\n",
    "has the authority to manage and oversee the use of AI or ADS by that entity or organization.''',\n",
    "        instruction = '''\\\n",
    "- First, answer only \"Yes\" or \"No\".\n",
    "- If \"Yes\", also include the name(s) of the governance body, \\\n",
    "label variable as `ai_governance_body_names`.'''\n",
    "    ),\n",
    "    dict(\n",
    "        name = \"has_harmonization\",\n",
    "        description = '''\\\n",
    "Indicates whether the bill outlines intent or strategy to harmonize legislation between state and federal government. \\\n",
    "Harmonization is defined as cooperation between different state and federal jurisdictions \\\n",
    "to make laws identical or at least more similar.''',\n",
    "        instruction = '''\\\n",
    "- First, answer only \"Yes\" or \"No\".\n",
    "- If \"Yes\", also include 1-2 sentence excerpts from the text to support existence of hamornization, \\\n",
    "label variable as `excerpt_harmonization`.'''\n",
    "    ),\n",
    "]\n",
    "\n",
    "definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3966689-a333-4415-8dcf-e609c4aa1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_str = '\\n'.join([\n",
    "'''\\\n",
    "{index}. `{name}`: {description}\n",
    "\n",
    "Instruction: \n",
    "{instruction}\n",
    "'''.format(**d, index=i+1)\n",
    "for i, d in enumerate(definitions)\n",
    "])\n",
    "\n",
    "print(def_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d4dee-4310-4160-ad3e-700bda06e375",
   "metadata": {},
   "source": [
    "## Create LLM chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f111a5d5-4a68-4ddd-8775-02a0e12d0dee",
   "metadata": {},
   "source": [
    "Note: Technically there are probably better ways to do this, like with structured data extraction & `pydandic`.\n",
    "\n",
    "The following uses summary chain with refinement instead as some documents are long and broken into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ac7d8-6d7c-448d-9173-e477ceaad236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: more models can be input here if need be\n",
    "llms = [\n",
    "    ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model_name=\"gpt-3.5-turbo-0125\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6096e83-ed8a-4b4b-bc16-153eccb6719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are a helpful assistant for legislators, researchers and lawyers.\n",
    "You are given a task to read a bill and extract necessary information from them.\n",
    "Below are the variables and instructions:\n",
    "\n",
    "%s \n",
    "\n",
    "Use only the definitions and follow instructions here.\n",
    "Only use the existing text as reference. Do not make things up.\n",
    "If you know an answer is empty, just use an empty string \"\". \n",
    "If you do not know an answer for a variable, just answer as \"unknown\".\n",
    "\n",
    "Please output as a JSON format.\n",
    "\n",
    "Here is the text:\n",
    "\n",
    "{text}\n",
    "\n",
    "JSON_OUTPUT:\"\"\" %(def_str)\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = '''\n",
    "Your job is extract necessary information about a bill.\n",
    "We have provided an existing JSON output up to a certain point: \n",
    "\n",
    "```json\n",
    "{existing_answer}\n",
    "```\n",
    "\n",
    "We have the opportunity to refine the existing JSON output\\\n",
    "(only if needed) with some more context below.\n",
    "------------\n",
    "{text}\n",
    "------------\n",
    "Given the new context, refine the original JSON output.\n",
    "If the context isn't useful, return the original JSON output.\n",
    "\n",
    "The final answer should be a JSON output with only these variables:\n",
    "\n",
    "%s\n",
    "''' %(def_str)\n",
    "\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "\n",
    "\n",
    "chains = []\n",
    "for llm in llms:\n",
    "    if hasattr(llm, 'model'):\n",
    "        model_source = llm.model\n",
    "    if hasattr(llm, 'model_name'):\n",
    "        model_source = llm.model_name\n",
    "    chains.append(dict(\n",
    "        model = model_source,\n",
    "        chain = load_summarize_chain(\n",
    "            llm=llm,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=prompt,\n",
    "            refine_prompt=refine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "            input_key=\"input_documents\",\n",
    "            output_key=\"output_text\",\n",
    "        )\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b041155-ef59-4072-a979-9c3e02f8023c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T17:16:41.760389Z",
     "iopub.status.busy": "2024-04-16T17:16:41.760065Z",
     "iopub.status.idle": "2024-04-16T17:16:41.763754Z",
     "shell.execute_reply": "2024-04-16T17:16:41.762879Z",
     "shell.execute_reply.started": "2024-04-16T17:16:41.760359Z"
    }
   },
   "source": [
    "## Extract from chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccce23-af3b-4db4-bb37-fd7fd4e4a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = dict()\n",
    "\n",
    "for i, bill in tqdm(enumerate(docs), total = len(docs)):\n",
    "    bill_id = bill['bill_id']\n",
    "    for chain_dict in chains:\n",
    "        model = chain_dict['model']\n",
    "        chain = chain_dict['chain']\n",
    "        \n",
    "        outkey = (model, bill_id)\n",
    "        if outkey in outputs:\n",
    "            continue\n",
    "        \n",
    "        result = chain({\"input_documents\": bill['chunks']})\n",
    "        outputs[outkey] = dict(\n",
    "            model = model,\n",
    "            bill_id = bill_id,\n",
    "            extraction = result['output_text'],\n",
    "            metadata = bill['metadata']\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ebc43-ebd8-4f82-896f-bec9e0048e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in outputs.items():\n",
    "    assert k == (v['model'], v['bill_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174036d-6f78-4628-9b51-ffdb145641d7",
   "metadata": {},
   "source": [
    "## Process output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a073ce-fbad-4e3c-88c2-45a65c6bcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = pd.DataFrame([dict(\n",
    "    bill_id = x['bill_id'],\n",
    "    model = x['model'],\n",
    "    **{\n",
    "        k: v for k, v in x['metadata'].items()\n",
    "        if k in  [\n",
    "            'session', \n",
    "            'classification',\n",
    "            'jurisdiction',\n",
    "            'jurisdiction_code',\n",
    "            'introduced_chamber',\n",
    "            'first_date',\n",
    "            'title',\n",
    "            'curated',\n",
    "            'has_ai_ads'\n",
    "        ]\n",
    "    },\n",
    "    **json.loads(\n",
    "        re.search(r'{((.|\\n)+)}', x['extraction']).group()\n",
    "    )\n",
    ") for x in outputs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282e1e7-f157-494e-93cd-151369edec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in dfe.filter(regex='has_|is_').columns:\n",
    "    if dfe[k].dtype == bool:\n",
    "        continue\n",
    "    dfe[k] = (\n",
    "        dfe[k].str.upper()\n",
    "        .fillna('NO')\n",
    "        .map({\n",
    "            '': False, \n",
    "            'NO': False, \n",
    "            'YES': True\n",
    "        })\n",
    "    )\n",
    "\n",
    "\n",
    "dfe['ai_governance_body_names'] = dfe['ai_governance_body_names'].fillna('').apply(\n",
    "    lambda x: x.title() if isinstance(x, str) else '; '.join(x).title()\n",
    ")\n",
    "\n",
    "dfe['excerpt_government_scope'] = dfe['excerpt_government_scope'].fillna('')\n",
    "dfe['excerpt_harmonization'] = dfe['excerpt_harmonization'].fillna('')\n",
    "\n",
    "assert all(dfe['has_government_scope'] == (dfe['excerpt_government_scope'] != \"\"))\n",
    "assert all(dfe['has_ai_governance_body'] == (dfe['ai_governance_body_names'] != \"\"))\n",
    "assert all(dfe['has_harmonization'] == (dfe['excerpt_harmonization'] != \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c73c6-707b-48c3-a484-ec2b89f45dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954ba7d-28d0-487f-b1fd-cf451ca455c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    dfe['has_ai_governance_body'].unique(),\n",
    "    dfe['has_government_scope'].unique(),\n",
    "    dfe['has_harmonization'].unique()    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7deef2-d166-4d5b-9514-be1389ef3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.to_csv('data/memo-criteria-extract.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "scenes_data": {
   "active_scene": "Default Scene",
   "init_scene": "",
   "scenes": [
    "Default Scene"
   ]
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
