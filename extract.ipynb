{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b245cc6b-8533-4512-89b8-65120828c515",
   "metadata": {},
   "source": [
    "# Use LLM to extract certain data based on definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2fb6ac-f38c-443c-8f13-502c462b6000",
   "metadata": {},
   "source": [
    "This notebook reads in certain state bills and uses LLM to extract certain data based on some definitions, e.g. whether a bill's scope is on government's use of AI/ADS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d0870-36a8-4572-9801-d02eded69ed6",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adda552-2225-414e-8eb9-99c0e121056a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997fddda-1c78-4d44-bfa7-5900dbef25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515d67d-7fc6-40d4-82c6-07849c6165a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7011eed2-384e-41d2-a0f2-e7781db94875",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_texts = (\n",
    "    pd.DataFrame(procsum)\n",
    "    .set_index('openstates_id')\n",
    "    [['bill_id', 'jurisdiction', 'session', 'progress', 'openai_summary']]\n",
    "    .apply(\n",
    "    lambda x: '''\\\n",
    "Bill ID: {bill_id}\n",
    "Jurisdiction: {jurisdiction}\n",
    "Session: {session}\n",
    "Bill progress: {progress} %\n",
    "Summary:\n",
    "{openai_summary}\n",
    "\n",
    "'''.format(**x),\n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1dcdc2-16cd-4009-8dd0-0ec7def5f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_source = 'zeroshotv1-bertopics'\n",
    "topic_file = f'data/proc/01-topics/{topic_source}/doc-topic-prob.csv'\n",
    "thres_over_chance = 3\n",
    "max_prob_thres = 0.9\n",
    "\n",
    "df_ids = df['openstates_id']\n",
    "topic_df = (\n",
    "    pd.read_csv(topic_file)\n",
    "    .set_index('openstates_id')\n",
    "    .loc[df_ids]\n",
    "    .drop(columns=['bill_id'])\n",
    ")\n",
    "chance_level = 1 / len(topic_df.columns)\n",
    "thres_prob = min(thres_over_chance * chance_level, max_prob_thres)\n",
    "\n",
    "topic_dict = (\n",
    "    topic_df\n",
    "    .melt(\n",
    "        var_name='topic',\n",
    "        value_name='prob',\n",
    "        ignore_index=False\n",
    "    )\n",
    "    .query('prob > @thres_prob')\n",
    "    .reset_index()\n",
    "    .groupby('topic')\n",
    "    ['openstates_id']\n",
    "    .agg(list)\n",
    "    .to_dict()\n",
    ")\n",
    "topics = list(topic_dict.keys())\n",
    "\n",
    "print(f'''\\\n",
    "Topic source = \"{topic_source}\" \n",
    "Number of topics = {len(topics)}\n",
    "Number of bills from `df` = {len(df)}\n",
    "Number of bills after applying topics threshold = {len(set(np.concatenate(list(topic_dict.values()))))}\\\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f171dc-a07c-47ab-8c7f-2108d4e4bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_source = 'zeroshotv2-bertopics'\n",
    "topic_file = f'data/proc/01-topics/{topic_source}/doc-topic-prob.csv'\n",
    "thres_over_chance = 3\n",
    "max_prob_thres = 0.7\n",
    "\n",
    "df_ids = df['openstates_id']\n",
    "topic_df = (\n",
    "    pd.read_csv(topic_file)\n",
    "    .set_index('openstates_id')\n",
    "    .loc[df_ids]\n",
    "    .drop(columns=['bill_id'])\n",
    ")\n",
    "chance_level = 1 / len(topic_df.columns)\n",
    "thres_prob = min(thres_over_chance * chance_level, max_prob_thres)\n",
    "\n",
    "topic_dict = (\n",
    "    topic_df\n",
    "    .melt(\n",
    "        var_name='topic',\n",
    "        value_name='prob',\n",
    "        ignore_index=False\n",
    "    )\n",
    "    .query('prob > @thres_prob')\n",
    "    .reset_index()\n",
    "    .groupby('topic')\n",
    "    ['openstates_id']\n",
    "    .agg(list)\n",
    "    .to_dict()\n",
    ")\n",
    "topics = list(topic_dict.keys())\n",
    "\n",
    "print(f'''\\\n",
    "Topic source = \"{topic_source}\" \n",
    "Number of topics = {len(topics)}\n",
    "Number of bills from `df` = {len(df)}\n",
    "Number of bills after applying topics threshold = {len(set(np.concatenate(list(topic_dict.values()))))}\\\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818656ea-38e4-4b7f-be0a-20f2aa5a5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_docs = dict()\n",
    "max_bills_per_chunk = 40\n",
    "\n",
    "for topic, os_ids in topic_dict.items():\n",
    "    num_bills = len(os_ids)\n",
    "    batch_ids = np.array_split(np.array(os_ids), int(np.ceil(num_bills / max_bills_per_chunk)))\n",
    "    topic_docs[topic] = []\n",
    "    for ids in batch_ids:\n",
    "        sum_texts = '\\n'.join(summary_texts.loc[ids])\n",
    "        topic_docs[topic].append(Document(\n",
    "            page_content = sum_texts,\n",
    "            metadata = dict(\n",
    "                topic = topic,\n",
    "                topic_source = topic_source,\n",
    "                openstates_ids = ids,\n",
    "            )\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06122ec9-18c1-4e8b-b9d2-da159ee68bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: len(v) for k, v in topic_docs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6899c8-89a9-4f25-ae11-084e4afac24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_summaries = []\n",
    "for topic, docs in tqdm(topic_docs.items(), total=len(topic_docs)):\n",
    "    prompt_template = \"\"\"You are a helpful assistant for legislators and researchers. \n",
    "    Write a concise summary about the topic %s of the bills, and if needed give examples of bills:\n",
    "    {text}\n",
    "    CONCISE SUMMARY:\"\"\" %(topic)\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    refine_template = (\n",
    "        \"Your job is to produce a final summary of the bills about the topic \" + topic + \"\\n\"\n",
    "        \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "        \"We have the opportunity to refine the existing summary\"\n",
    "        \"(only if needed) with some more context below.\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"{text}\\n\"\n",
    "        \"------------\\n\"\n",
    "        \"Given the new context, refine the original summary.\"\n",
    "        \"If the context isn't useful, return the original summary.\"\n",
    "        \"If needed, provide some bill examples.\"\n",
    "        \"The final output should have between 10 to 20 sentences.\"\n",
    "    )\n",
    "\n",
    "    refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "    chain = load_summarize_chain(\n",
    "        llm=llm,\n",
    "        chain_type=\"refine\",\n",
    "        question_prompt=prompt,\n",
    "        refine_prompt=refine_prompt,\n",
    "        return_intermediate_steps=True,\n",
    "        input_key=\"input_documents\",\n",
    "        output_key=\"output_text\",\n",
    "    )\n",
    "    result = chain({\"input_documents\": docs})\n",
    "    topic_summaries.append(dict(\n",
    "        topic = topic,\n",
    "        topic_source = topic_source,\n",
    "        result = result\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a6b13-7b40-421e-a618-a0945906f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.json_normalize(topic_summaries, sep='_')\n",
    "    .drop(columns=['result_input_documents', 'result_intermediate_steps'])\n",
    "    .to_json(f'data/proc/02-summary/summary-topic-{topic_source}.json')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b7f23-0386-48c9-9b41-06a778327435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73471134-9ccb-4b5f-8656-c7b97aa8ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/proc/02-summary/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde6962-b18a-4e63-8f60-75d869fb1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in topic_summaries:\n",
    "    print(x['topic'].upper())\n",
    "    print(x['result']['output_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e090ce-407b-490f-9ac4-fb2d120cd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/proc/02-summary/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f82cc28-11e8-4f49-a5c3-09194d26bb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872726b2-3a03-4c91-883e-31878e0ad3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.concat([\n",
    "    pd.read_json('data/proc/02-summary/summary-topic-zeroshotv1-bertopics.json'),\n",
    "    pd.read_json('data/proc/02-summary/summary-topic-zeroshotv2-bertopics.json')\n",
    "], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e44c1-54d0-4a16-9b68-a99de34df60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df['result_output_text'].loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276b5f6-6539-4b19-8475-e0185651ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_template = r'''---\n",
    "geometry:\n",
    "    - margin=0.5in\n",
    "output: pdf_document\n",
    "colorlinks: true\n",
    "fontsize: 9pt\n",
    "toc: false\n",
    "urlcolor: \"violet\"\n",
    "header-includes:\n",
    "    - \\usepackage{titling}\n",
    "    - \\setlength{\\droptitle}{-7em}\n",
    "    - \\pagenumbering{gobble}\n",
    "    - \\setlength{\\parindent}{0em}\n",
    "    - \\usepackage{sansmathfonts}\n",
    "    - \\usepackage[T1]{fontenc}\n",
    "    - \\renewcommand*\\familydefault{\\sfdefault} \n",
    "    - \\usepackage{wrapfig}\n",
    "    - \\usepackage{booktabs}\n",
    "    - \\usepackage[export]{adjustbox}\n",
    "    - \\newcommand{\\forceindent}{\\leavevmode{\\parindent=1em\\indent}}\n",
    "    - \\usepackage{fvextra}\n",
    "    - \\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}\n",
    "---\n",
    "'''\n",
    "\n",
    "text = yaml_template + '''\\\n",
    "\n",
    "# Demonstrative summary of bills (from 2023-2024) based on topics\n",
    "\n",
    "## Method\n",
    "\n",
    "### Initial summary\n",
    "\n",
    "These are early summarization attempts of bills using OpenAI ChatGPT with the following prompt:\n",
    "\n",
    "> *You are a helpful assistant for legislators and researchers.*\n",
    ">\n",
    "> *Write a concise bullet point summary of the following text, keep it maximum 10 bullet points and do not repeat:*\n",
    ">\n",
    "> `TEXT`\n",
    "\n",
    "### Topic summary\n",
    "\n",
    "Because each bill can usually be assigned a topic (or a few) using topic modelling, we can summarize the resulting summaries for each topic, with some \"targeting/focusing\".\n",
    "\n",
    "Below is part of an example starting prompt:\n",
    "\n",
    "> *You are a helpful assistant for legislators and researchers*.\n",
    ">\n",
    "> *Write a concise summary about the topic **Algorithmic Discrimination or Auditing** of the bills, and if needed give examples of bills*.\n",
    "> \n",
    "> `TEXT`\n",
    "\n",
    "Because of the limits of context for using LLM, we'd have to split into chunks of text, summarize them (i.e. summarize subsets of initial summaries), and refine the process.\n",
    "\n",
    "Below is the prompt for refinement, also topic-focused:\n",
    "\n",
    "> *Your job is to produce a final summary of the bills about the topic **Algorithmic Discrimination or Auditing***.\n",
    ">\n",
    "> *We have provided an existing summary up to a certain point*: `EXISTING_ANSWER`.\n",
    ">\n",
    "> *We have the opportunity to refine the existing summary (only if needed) with some more context below.*\n",
    ">\n",
    "> *Given the new context, refine the original summary.*\n",
    ">\n",
    "> `TEXT`\n",
    ">\n",
    "> *If the context isn't useful, return the original summary.*\n",
    ">\n",
    "> *If needed, provide some bill examples.*\n",
    ">\n",
    "> *The final output should have between 10 to 20 sentences.*\n",
    "\n",
    "Note: some of the formating and variables of the actual prompts have been changed here to highlight the ideas of the prompts being used, not the exact copies of the prompts.\n",
    "\n",
    "'''\n",
    "\n",
    "source_explanations = {\n",
    "    'zeroshotv1-bertopics': 'These topics are curated from Citris Policy Lab, with some modifications from early iteration of our AI legislative tracker.',\n",
    "    'zeroshotv2-bertopics': 'These topics are curated from our ongoing Scorecard Devlopment categories.'\n",
    "}\n",
    "for source in ts_df['topic_source'].unique():\n",
    "    text += f'## Topic source from: `{source}`\\n{source_explanations[source]}\\n\\n'\n",
    "    \n",
    "    for i, row in ts_df.query('topic_source == @source').reset_index(drop=True).iterrows():\n",
    "        text += f'### {i+1}. {row[\"topic\"]}\\n\\n'\n",
    "        text += re.sub(\n",
    "            r'([A-Z]{2}_\\[[^\\]]+\\]_[A-Z][-_\\s]?\\w+)',\n",
    "            r'`\\1`',\n",
    "            row['result_output_text']\n",
    "        ) + '\\n\\n'\n",
    "        \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c697614-5522-47c3-8ad0-4fc232a2a594",
   "metadata": {},
   "source": [
    "## Read and select data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f4ca7-9e31-458a-b471-3b9fb6792b5f",
   "metadata": {},
   "source": [
    "The following selects curated data (i.e. bills that have met certain threshold of AI/ADS-related words, usually relative to the length of the document). However, to widen the search, below also attempts to included bills not marked by such curation based on threshold, as long as they contain `artificial intelligence` or `automat(ed|ic) decision`. Additionally, only **state** bills proposed from 2023-2024 are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfabfb-53f9-4867-92f8-323012e727ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/bill_data.json')\n",
    "df['text'] = df['text'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cef1dd-67f6-49ef-a2cc-63df9a0fed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_ai_ads'] = ~df.filter(regex='^query_').agg(\n",
    "    lambda x: ' '.join(list(set(np.concatenate(list(x))))),\n",
    "    axis=1\n",
    ").str.extract(\n",
    "    r'(artificial intelligence|automat\\w* decision)',\n",
    "    expand=False\n",
    ").isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4d7b0-48da-4ba0-a934-355c202e7b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .query(\n",
    "        '''\n",
    "        (curated or has_ai_ads)\n",
    "        and\n",
    "        first_date.str.contains(\"2023|2024\", regex=True)\n",
    "        and \n",
    "        jurisdiction_code != \"US\"\n",
    "    '''.replace('\\n',' ').strip()\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2455e2-7e97-48e3-a607-60a57edf3f59",
   "metadata": {},
   "source": [
    "## Split text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff5533-3ccc-44a7-9c58-d5bcceba5c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T17:21:49.064336Z",
     "iopub.status.busy": "2024-04-16T17:21:49.063897Z",
     "iopub.status.idle": "2024-04-16T17:21:49.070285Z",
     "shell.execute_reply": "2024-04-16T17:21:49.068839Z",
     "shell.execute_reply.started": "2024-04-16T17:21:49.064296Z"
    },
    "tags": []
   },
   "source": [
    "Some bills are quite long, so break into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e05d9-abe1-42b6-8fbf-7cfb85f81d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=10000,\n",
    "    chunk_overlap=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176cf71-764a-4071-8fe6-d50e5711e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    metadata = {\n",
    "        k: v for k, v in row.items() \n",
    "        if k not in ['text', 'raw_text', 'abstract']\n",
    "    }\n",
    "    \n",
    "    chunks = text_splitter.split_documents([Document(page_content=text)])\n",
    "    docs.append(dict(\n",
    "        bill_id = metadata['bill_id'],\n",
    "        chunks = chunks,\n",
    "        metadata = metadata,\n",
    "        num_chunks = len(chunks)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52288755-8e27-4311-8e35-b88b49eb4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs), sum([len(x['chunks']) for x in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1161a3-93ea-4b6b-a27e-b33ef03850eb",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec429d93-b4b1-4b9e-b414-35f32dc6b446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T17:22:21.546907Z",
     "iopub.status.busy": "2024-04-16T17:22:21.546619Z",
     "iopub.status.idle": "2024-04-16T17:22:21.552072Z",
     "shell.execute_reply": "2024-04-16T17:22:21.550885Z",
     "shell.execute_reply.started": "2024-04-16T17:22:21.546880Z"
    },
    "tags": []
   },
   "source": [
    "These are some definitions and intructions to handle them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efc682-536d-4b30-a544-dd96dfb7401f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "definitions = [\n",
    "    dict(\n",
    "        name = \"has_government_scope\",\n",
    "        description = '''\\\n",
    "Indicates whether the bill has government scope: \\\n",
    "a bill has government scope if it governs the government's use of artificial intelligence (AI) or \\\n",
    "automated decision systems (ADS) in its operations. \\\n",
    "This scope specifically focuses on the **government**'s use and procurement of these technologies.''',\n",
    "        instruction = '''\\\n",
    "- First, answer only \"Yes\" or \"No\".\n",
    "- If \"Yes\", also include 1-2 sentence excerpts from the text to support the government scope, \\\n",
    "label variable as `excerpt_government_scope`.'''\n",
    "    ),\n",
    "    dict(\n",
    "        name = \"has_ai_governance_body\",\n",
    "        description = '''\\\n",
    "Indicates whether the bill designates, indicates or establishes an AI governance body: \\\n",
    "an AI governance body is a group of people in the within a government entity or organization that \\\n",
    "has the authority to manage and oversee the use of AI or ADS by that entity or organization.''',\n",
    "        instruction = '''\\\n",
    "- First, answer only \"Yes\" or \"No\".\n",
    "- If \"Yes\", also include the name(s) of the governance body, \\\n",
    "label variable as `ai_governance_body_names`.'''\n",
    "    ),\n",
    "    dict(\n",
    "        name = \"has_harmonization\",\n",
    "        description = '''\\\n",
    "Indicates whether the bill outlines intent or strategy to harmonize legislation between state and federal government. \\\n",
    "Harmonization is defined as cooperation between different state and federal jurisdictions \\\n",
    "to make laws identical or at least more similar.''',\n",
    "        instruction = '''\\\n",
    "- First, answer only \"Yes\" or \"No\".\n",
    "- If \"Yes\", also include 1-2 sentence excerpts from the text to support existence of hamornization, \\\n",
    "label variable as `excerpt_harmonization`.'''\n",
    "    ),\n",
    "]\n",
    "\n",
    "definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3966689-a333-4415-8dcf-e609c4aa1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_str = '\\n'.join([\n",
    "'''\\\n",
    "{index}. `{name}`: {description}\n",
    "\n",
    "Instruction: \n",
    "{instruction}\n",
    "'''.format(**d, index=i+1)\n",
    "for i, d in enumerate(definitions)\n",
    "])\n",
    "\n",
    "print(def_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d4dee-4310-4160-ad3e-700bda06e375",
   "metadata": {},
   "source": [
    "## Create LLM chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f111a5d5-4a68-4ddd-8775-02a0e12d0dee",
   "metadata": {},
   "source": [
    "Note: Technically there are probably better ways to do this, like with structured data extraction & `pydandic`.\n",
    "\n",
    "The following uses summary chain with refinement instead as some documents are long and broken into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ac7d8-6d7c-448d-9173-e477ceaad236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note: more models can be input here if need be\n",
    "llms = [\n",
    "    ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model_name=\"gpt-3.5-turbo-0125\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6096e83-ed8a-4b4b-bc16-153eccb6719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are a helpful assistant for legislators, researchers and lawyers.\n",
    "You are given a task to read a bill and extract necessary information from them.\n",
    "Below are the variables and instructions:\n",
    "\n",
    "%s \n",
    "\n",
    "Use only the definitions and follow instructions here.\n",
    "Only use the existing text as reference. Do not make things up.\n",
    "If you know an answer is empty, just use an empty string \"\". \n",
    "If you do not know an answer for a variable, just answer as \"unknown\".\n",
    "\n",
    "Please output as a JSON format.\n",
    "\n",
    "Here is the text:\n",
    "\n",
    "{text}\n",
    "\n",
    "JSON_OUTPUT:\"\"\" %(def_str)\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = '''\n",
    "Your job is extract necessary information about a bill.\n",
    "We have provided an existing JSON output up to a certain point: \n",
    "\n",
    "```json\n",
    "{existing_answer}\n",
    "```\n",
    "\n",
    "We have the opportunity to refine the existing JSON output\\\n",
    "(only if needed) with some more context below.\n",
    "------------\n",
    "{text}\n",
    "------------\n",
    "Given the new context, refine the original JSON output.\n",
    "If the context isn't useful, return the original JSON output.\n",
    "\n",
    "The final answer should be a JSON output with only these variables:\n",
    "\n",
    "%s\n",
    "''' %(def_str)\n",
    "\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "\n",
    "\n",
    "chains = []\n",
    "for llm in llms:\n",
    "    if hasattr(llm, 'model'):\n",
    "        model_source = llm.model\n",
    "    if hasattr(llm, 'model_name'):\n",
    "        model_source = llm.model_name\n",
    "    chains.append(dict(\n",
    "        model = model_source,\n",
    "        chain = load_summarize_chain(\n",
    "            llm=llm,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=prompt,\n",
    "            refine_prompt=refine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "            input_key=\"input_documents\",\n",
    "            output_key=\"output_text\",\n",
    "        )\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b041155-ef59-4072-a979-9c3e02f8023c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T17:16:41.760389Z",
     "iopub.status.busy": "2024-04-16T17:16:41.760065Z",
     "iopub.status.idle": "2024-04-16T17:16:41.763754Z",
     "shell.execute_reply": "2024-04-16T17:16:41.762879Z",
     "shell.execute_reply.started": "2024-04-16T17:16:41.760359Z"
    },
    "tags": []
   },
   "source": [
    "## Extract from chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccce23-af3b-4db4-bb37-fd7fd4e4a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = dict()\n",
    "\n",
    "for i, bill in tqdm(enumerate(docs), total = len(docs)):\n",
    "    bill_id = bill['bill_id']\n",
    "    for chain_dict in chains:\n",
    "        model = chain_dict['model']\n",
    "        chain = chain_dict['chain']\n",
    "        \n",
    "        outkey = (model, bill_id)\n",
    "        if outkey in outputs:\n",
    "            continue\n",
    "        \n",
    "        result = chain({\"input_documents\": bill['chunks']})\n",
    "        outputs[outkey] = dict(\n",
    "            model = model,\n",
    "            bill_id = bill_id,\n",
    "            extraction = result['output_text'],\n",
    "            metadata = bill['metadata']\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ebc43-ebd8-4f82-896f-bec9e0048e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in outputs.items():\n",
    "    assert k == (v['model'], v['bill_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174036d-6f78-4628-9b51-ffdb145641d7",
   "metadata": {},
   "source": [
    "## Process output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a073ce-fbad-4e3c-88c2-45a65c6bcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = pd.DataFrame([dict(\n",
    "    bill_id = x['bill_id'],\n",
    "    model = x['model'],\n",
    "    **{\n",
    "        k: v for k, v in x['metadata'].items()\n",
    "        if k in  [\n",
    "            'session', \n",
    "            'classification',\n",
    "            'jurisdiction',\n",
    "            'jurisdiction_code',\n",
    "            'introduced_chamber',\n",
    "            'first_date',\n",
    "            'title',\n",
    "            'curated',\n",
    "            'has_ai_ads'\n",
    "        ]\n",
    "    },\n",
    "    **json.loads(\n",
    "        re.search(r'{((.|\\n)+)}', x['extraction']).group()\n",
    "    )\n",
    ") for x in outputs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282e1e7-f157-494e-93cd-151369edec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in dfe.filter(regex='has_|is_').columns:\n",
    "    if dfe[k].dtype == bool:\n",
    "        continue\n",
    "    dfe[k] = (\n",
    "        dfe[k].str.upper()\n",
    "        .fillna('NO')\n",
    "        .map({\n",
    "            '': False, \n",
    "            'NO': False, \n",
    "            'YES': True\n",
    "        })\n",
    "    )\n",
    "\n",
    "\n",
    "dfe['ai_governance_body_names'] = dfe['ai_governance_body_names'].fillna('').apply(\n",
    "    lambda x: x.title() if isinstance(x, str) else '; '.join(x).title()\n",
    ")\n",
    "\n",
    "dfe['excerpt_government_scope'] = dfe['excerpt_government_scope'].fillna('')\n",
    "dfe['excerpt_harmonization'] = dfe['excerpt_harmonization'].fillna('')\n",
    "\n",
    "assert all(dfe['has_government_scope'] == (dfe['excerpt_government_scope'] != \"\"))\n",
    "assert all(dfe['has_ai_governance_body'] == (dfe['ai_governance_body_names'] != \"\"))\n",
    "assert all(dfe['has_harmonization'] == (dfe['excerpt_harmonization'] != \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c73c6-707b-48c3-a484-ec2b89f45dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954ba7d-28d0-487f-b1fd-cf451ca455c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    dfe['has_ai_governance_body'].unique(),\n",
    "    dfe['has_government_scope'].unique(),\n",
    "    dfe['has_harmonization'].unique()    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7deef2-d166-4d5b-9514-be1389ef3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.to_csv('data/memo-criteria-extract.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "scenes_data": {
   "active_scene": "Default Scene",
   "init_scene": "",
   "scenes": [
    "Default Scene"
   ]
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
